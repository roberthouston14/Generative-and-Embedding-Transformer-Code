{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FbK3lE2L2MjgeRJtKR_1kaveeuhCxNPp",
      "authorship_tag": "ABX9TyPJTWd4yAsjhybNhfUPgzhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roberthouston14/Final_Praxis_Code/blob/main/Traditional_Data_Balancers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-YUnJyZza2t",
        "outputId": "404a6e74-973e-4464-f753-3d2a2ece3fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load all necessary libraries\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import random\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "# from collections import Counter\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.utils import resample\n",
        "\n",
        "# # Connect to gdrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Prompt user for input file\n",
        "# input_file = input(\"Enter the name of the input file: \")\n",
        "\n",
        "# # Prompt user for column name of the text data\n",
        "# text_column = input(\"Enter the name of the text column: \")\n",
        "\n",
        "# # Prompt user for the column name of the binary labels\n",
        "# label_column = input(\"Enter the name of the label column: \")\n",
        "\n",
        "# # Load the CSV file into a Pandas DataFrame\n",
        "# df = pd.read_csv(input_file)\n",
        "\n",
        "# # Count the number of rows in each label category\n",
        "# class_counts = df[label_column].value_counts()\n",
        "\n",
        "# # Upsample the minority class\n",
        "# minority = df[df[label_column] == 1]\n",
        "# upsampled = resample(minority, replace=True, n_samples=class_counts[0], random_state=42)\n",
        "# upsampled_df = pd.concat([upsampled, df[df[label_column] == 0]])\n",
        "\n",
        "# # Downsample the majority class\n",
        "# majority = df[df[label_column] == 0]\n",
        "# downsampled = resample(majority, replace=False, n_samples=class_counts[1], random_state=42)\n",
        "# downsampled_df = pd.concat([downsampled, df[df[label_column] == 1]])\n",
        "\n",
        "# # Save the upsampled and downsampled dataframes to CSV files\n",
        "# upsampled_file = os.path.splitext(input_file)[0] + \"_upsampled.csv\"\n",
        "# upsampled_df.to_csv(upsampled_file, index=False)\n",
        "\n",
        "# downsampled_file = os.path.splitext(input_file)[0] + \"_downsampled.csv\"\n",
        "# downsampled_df.to_csv(downsampled_file, index=False)\n",
        "\n",
        "# # Use SMOTE to achieve 50/50 balance in the dataset\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "# smote_texts = [' '.join(text) for text in vectorizer.inverse_transform(X_resampled)]\n",
        "# smote_df = pd.DataFrame({text_column: smote_texts, label_column: y_resampled})\n",
        "# smote_file = os.path.splitext(input_file)[0] + \"_SMOTE.csv\"\n",
        "# smote_df.to_csv(smote_file, index=False)\n",
        "\n",
        "\n",
        "# # Print summary table\n",
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Original Dataset: {input_file}\")\n",
        "# print(f\"Total Rows: {len(df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"Downsampled Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Downsampled Dataset: {undersampled_file}\")\n",
        "# print(f\"Total Rows: {len(undersampled_df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(undersampled_df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - undersampled_df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"Upsampled Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Upsampled Dataset: {oversampled_file}\")\n",
        "# print(f\"Total Rows: {len(oversampled_df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(oversampled_df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - oversampled_df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"SMOTE Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"SMOTE Dataset: {smote_file}\")\n",
        "# print(f\"Total Rows: {len(smote_df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(smote_df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - smote_df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjYejITh3VNf",
        "outputId": "253a2943-7de8-4432-c737-d999916e44d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the name of the input file: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam.csv\n",
            "Enter the name of the text column: sms\n",
            "Enter the name of the label column: label\n",
            "\n",
            "================================================================================\n",
            "                                Dataset Summary                                 \n",
            "================================================================================\n",
            "Original Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam.csv\n",
            "Total Rows: 5574\n",
            "Ratio of class entries (1's): 0.13\n",
            "Ratio of class entries (0's): 0.87\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          Downsampled Dataset Summary                           \n",
            "================================================================================\n",
            "Downsampled Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_downsampled.csv\n",
            "Total Rows: 1494\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           Upsampled Dataset Summary                            \n",
            "================================================================================\n",
            "Upsampled Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_upsampled.csv\n",
            "Total Rows: 9654\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             SMOTE Dataset Summary                              \n",
            "================================================================================\n",
            "SMOTE Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_SMOTE.csv\n",
            "Total Rows: 9654\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load all necessary libraries\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import random\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "# from collections import Counter\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.utils import resample\n",
        "\n",
        "# # Connect to gdrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Prompt user for input file\n",
        "# input_file = input(\"Enter the name of the input file: \")\n",
        "\n",
        "# # Prompt user for column name of the text data\n",
        "# text_column = input(\"Enter the name of the text column: \")\n",
        "\n",
        "# # Prompt user for the column name of the binary labels\n",
        "# label_column = input(\"Enter the name of the label column: \")\n",
        "\n",
        "# # Load the CSV file into a Pandas DataFrame\n",
        "# df = pd.read_csv(input_file)\n",
        "\n",
        "# # Count the number of rows in each label category\n",
        "# class_counts = df[label_column].value_counts()\n",
        "\n",
        "# # Upsample the minority class\n",
        "# minority = df[df[label_column] == 1]\n",
        "# upsampled = resample(minority, replace=True, n_samples=class_counts[0], random_state=42)\n",
        "# upsampled_df = pd.concat([upsampled, df[df[label_column] == 0]])\n",
        "\n",
        "# # Downsample the majority class\n",
        "# majority = df[df[label_column] == 0]\n",
        "# downsampled = resample(majority, replace=False, n_samples=class_counts[1], random_state=42)\n",
        "# downsampled_df = pd.concat([downsampled, df[df[label_column] == 1]])\n",
        "\n",
        "# # Save the upsampled and downsampled dataframes to CSV files\n",
        "# upsampled_file = os.path.splitext(input_file)[0] + \"_upsampled.csv\"\n",
        "# upsampled_df.to_csv(upsampled_file, index=False)\n",
        "\n",
        "# downsampled_file = os.path.splitext(input_file)[0] + \"_downsampled.csv\"\n",
        "# downsampled_df.to_csv(downsampled_file, index=False)\n",
        "\n",
        "# # Use SMOTE to achieve 50/50 balance in the dataset\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "# smote_texts = [' '.join(text) for text in vectorizer.inverse_transform(X_resampled)]\n",
        "# smote_df = pd.DataFrame({text_column: smote_texts, label_column: y_resampled})\n",
        "\n",
        "# # Drop rows with NaN values\n",
        "# smote_df.dropna(inplace=True)\n",
        "\n",
        "# smote_file = os.path.splitext(input_file)[0] + \"_SMOTE.csv\"\n",
        "# smote_df.to_csv(smote_file, index=False)\n",
        "\n",
        "# # Print summary table\n",
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Original Dataset: {input_file}\")\n",
        "# print(f\"Total Rows: {len(df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"Downsampled Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Downsampled Dataset: {undersampled_file}\")\n",
        "# print(f\"Total Rows: {len(undersampled_df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(undersampled_df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - undersampled_df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"Upsampled Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Upsampled Dataset: {oversampled_file}\")\n",
        "# print(f\"Total Rows: {len(oversampled_df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(oversampled_df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - oversampled_df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")\n",
        "\n",
        "# print(\"=\"*80)\n",
        "# print(\"SMOTE Dataset Summary\".center(80))\n",
        "# print(\"=\"*80)\n",
        "# print(f\"SMOTE Dataset: {smote_file}\")\n",
        "# print(f\"Total Rows: {len(smote_df)}\")\n",
        "# print(f\"Ratio of class entries (1's): {round(smote_df[label_column].mean(), 2)}\")\n",
        "# print(f\"Ratio of class entries (0's): {round(1 - smote_df[label_column].mean(), 2)}\")\n",
        "# print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoUkanEdODNL",
        "outputId": "34af4e92-a72b-4ffc-91f5-5b2f70982b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the name of the input file: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam.csv\n",
            "Enter the name of the text column: sms\n",
            "Enter the name of the label column: label\n",
            "\n",
            "================================================================================\n",
            "                                Dataset Summary                                 \n",
            "================================================================================\n",
            "Original Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam.csv\n",
            "Total Rows: 5574\n",
            "Ratio of class entries (1's): 0.13\n",
            "Ratio of class entries (0's): 0.87\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          Downsampled Dataset Summary                           \n",
            "================================================================================\n",
            "Downsampled Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_downsampled.csv\n",
            "Total Rows: 1494\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           Upsampled Dataset Summary                            \n",
            "================================================================================\n",
            "Upsampled Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_upsampled.csv\n",
            "Total Rows: 9654\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             SMOTE Dataset Summary                              \n",
            "================================================================================\n",
            "SMOTE Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_SMOTE.csv\n",
            "Total Rows: 9654\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Prompt user for input file\n",
        "input_file = input(\"Enter the name of the input file: \")\n",
        "\n",
        "# Prompt user for column name of the text data\n",
        "text_column = input(\"Enter the name of the text column: \")\n",
        "\n",
        "# Prompt user for the column name of the binary labels\n",
        "label_column = input(\"Enter the name of the label column: \")\n",
        "\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Count the number of rows in each label category\n",
        "class_counts = df[label_column].value_counts()\n",
        "\n",
        "# Upsample the minority class\n",
        "minority = df[df[label_column] == 1]\n",
        "upsampled = resample(minority, replace=True, n_samples=class_counts[0], random_state=42)\n",
        "upsampled_df = pd.concat([upsampled, df[df[label_column] == 0]])\n",
        "\n",
        "# Downsample the majority class\n",
        "majority = df[df[label_column] == 0]\n",
        "downsampled = resample(majority, replace=False, n_samples=class_counts[1], random_state=42)\n",
        "downsampled_df = pd.concat([downsampled, df[df[label_column] == 1]])\n",
        "\n",
        "# Save the upsampled and downsampled dataframes to CSV files\n",
        "upsampled_file = os.path.splitext(input_file)[0] + \"_upsampled.csv\"\n",
        "upsampled_df.to_csv(upsampled_file, index=False)\n",
        "\n",
        "downsampled_file = os.path.splitext(input_file)[0] + \"_downsampled.csv\"\n",
        "downsampled_df.to_csv(downsampled_file, index=False)\n",
        "\n",
        "# Use SMOTE to achieve 50/50 balance in the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Check for NaN values in the input data\n",
        "assert pd.DataFrame(X.toarray()).isna().sum().sum() == 0, \"X contains NaN values.\"\n",
        "assert y.isna().sum().sum() == 0, \"y contains NaN values.\"\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Ensure the inverse_transform function returns proper strings\n",
        "smote_texts = [' '.join(text) if len(text) > 0 else '' for text in vectorizer.inverse_transform(X_resampled)]\n",
        "\n",
        "smote_df = pd.DataFrame({text_column: smote_texts, label_column: y_resampled})\n",
        "\n",
        "# Drop rows with NaN values\n",
        "smote_df.dropna(inplace=True)\n",
        "\n",
        "# Check for NaN values in the dataframe\n",
        "num_nans = smote_df.isna().sum().sum()\n",
        "\n",
        "# Drop rows that don't have at least one word in the 'sms' column\n",
        "smote_df = smote_df[smote_df[text_column].str.strip().str.len() > 0]\n",
        "\n",
        "# Prompt user to drop NaN rows if any exist\n",
        "if num_nans > 0:\n",
        "    print(f\"The SMOTE-generated dataset contains {num_nans} NaN values.\")\n",
        "    drop_nans = input(\"Do you want to drop the corresponding rows? (y/n): \")\n",
        "    if drop_nans.lower() == \"y\":\n",
        "        smote_df.dropna(inplace=True)\n",
        "        num_nans = smote_df.isna().sum().sum()\n",
        "        print(f\"{num_nans} NaN values were removed.\")\n",
        "    else:\n",
        "        print(\"No rows were dropped.\")\n",
        "\n",
        "smote_file = os.path.splitext(input_file)[0] + \"_SMOTE.csv\"\n",
        "smote_df.to_csv(smote_file, index=False)\n",
        "\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Original Dataset: {input_file}\")\n",
        "print(f\"Total Rows: {len(df)}\")\n",
        "print(f\"Ratio of class entries (1's): {round(df[label_column].mean(), 2)}\")\n",
        "print(f\"Ratio of class entries (0's): {round(1 - df[label_column].mean(), 2)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Downsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Downsampled Dataset: {undersampled_file}\")\n",
        "print(f\"Total Rows: {len(undersampled_df)}\")\n",
        "print(f\"Ratio of class entries (1's): {round(undersampled_df[label_column].mean(), 2)}\")\n",
        "print(f\"Ratio of class entries (0's): {round(1 - undersampled_df[label_column].mean(), 2)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Upsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Upsampled Dataset: {oversampled_file}\")\n",
        "print(f\"Total Rows: {len(oversampled_df)}\")\n",
        "print(f\"Ratio of class entries (1's): {round(oversampled_df[label_column].mean(), 2)}\")\n",
        "print(f\"Ratio of class entries (0's): {round(1 - oversampled_df[label_column].mean(), 2)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SMOTE Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"SMOTE Dataset: {smote_file}\")\n",
        "print(f\"Total Rows: {len(smote_df)}\")\n",
        "print(f\"Ratio of class entries (1's): {round(smote_df[label_column].mean(), 2)}\")\n",
        "print(f\"Ratio of class entries (0's): {round(1 - smote_df[label_column].mean(), 2)}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cWP9BpgOW9a",
        "outputId": "603b59ce-6839-4655-f24a-d04e9d9ee002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the name of the input file: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam.csv\n",
            "Enter the name of the text column: sms\n",
            "Enter the name of the label column: label\n",
            "\n",
            "================================================================================\n",
            "                                Dataset Summary                                 \n",
            "================================================================================\n",
            "Original Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam.csv\n",
            "Total Rows: 5574\n",
            "Ratio of class entries (1's): 0.13\n",
            "Ratio of class entries (0's): 0.87\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          Downsampled Dataset Summary                           \n",
            "================================================================================\n",
            "Downsampled Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_downsampled.csv\n",
            "Total Rows: 1494\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           Upsampled Dataset Summary                            \n",
            "================================================================================\n",
            "Upsampled Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_upsampled.csv\n",
            "Total Rows: 9654\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             SMOTE Dataset Summary                              \n",
            "================================================================================\n",
            "SMOTE Dataset: /content/drive/MyDrive/Production Datasets/sms_spam/sms_spam_SMOTE.csv\n",
            "Total Rows: 9650\n",
            "Ratio of class entries (1's): 0.5\n",
            "Ratio of class entries (0's): 0.5\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is the 3 class version of the data balancer software"
      ],
      "metadata": {
        "id": "Gdxirn1ZQ3kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Prompt user for input file\n",
        "input_file = input(\"Enter the name of the input file: \")\n",
        "\n",
        "# Prompt user for column name of the text data\n",
        "text_column = input(\"Enter the name of the text column: \")\n",
        "\n",
        "# Prompt user for the column name of the binary labels\n",
        "label_column = input(\"Enter the name of the label column: \")\n",
        "\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Convert class names to lowercase\n",
        "df[label_column] = df[label_column].str.lower()\n",
        "\n",
        "# Recalculate class counts and ratios\n",
        "class_counts = df[label_column].value_counts()\n",
        "\n",
        "\n",
        "# Count the number of rows in each label category\n",
        "class_counts = df[label_column].value_counts()\n",
        "\n",
        "# Find the size of the largest and smallest class\n",
        "max_class_size = class_counts.max()\n",
        "min_class_size = class_counts.min()\n",
        "\n",
        "# Upsample the minority classes\n",
        "upsampled_df = pd.DataFrame()\n",
        "for class_value in class_counts.index:\n",
        "    class_data = df[df[label_column] == class_value]\n",
        "    upsampled_data = resample(class_data, replace=True, n_samples=max_class_size, random_state=42)\n",
        "    upsampled_df = pd.concat([upsampled_df, upsampled_data])\n",
        "\n",
        "# Downsample the majority class\n",
        "downsampled_df = pd.DataFrame()\n",
        "for class_value in class_counts.index:\n",
        "    class_data = df[df[label_column] == class_value]\n",
        "    downsampled_data = resample(class_data, replace=False, n_samples=min_class_size, random_state=42)\n",
        "    downsampled_df = pd.concat([downsampled_df, downsampled_data])\n",
        "\n",
        "# Save the upsampled and downsampled dataframes to CSV files\n",
        "upsampled_file = os.path.splitext(input_file)[0] + \"_upsampled.csv\"\n",
        "upsampled_df.to_csv(upsampled_file, index=False)\n",
        "\n",
        "downsampled_file = os.path.splitext(input_file)[0] + \"_downsampled.csv\"\n",
        "downsampled_df.to_csv(downsampled_file, index=False)\n",
        "\n",
        "# Use SMOTE to achieve balance in the dataset\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[text_column])\n",
        "y = df[label_column]\n",
        "\n",
        "# Check for NaN values in the input data\n",
        "assert pd.DataFrame(X.toarray()).isna().sum().sum() == 0, \"X contains NaN values.\"\n",
        "assert y.isna().sum().sum() == 0, \"y contains NaN values.\"\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Ensure the inverse_transform function returns proper strings\n",
        "smote_texts = [' '.join(text) if len(text) > 0 else '' for text in vectorizer.inverse_transform(X_resampled)]\n",
        "\n",
        "smote_df = pd.DataFrame({text_column: smote_texts, label_column: y_resampled})\n",
        "\n",
        "# Drop rows with NaN values\n",
        "smote_df.dropna(inplace=True)\n",
        "\n",
        "# Check for NaN values in the dataframe\n",
        "num_nans = smote_df.isna().sum().sum()\n",
        "\n",
        "# Drop rows that don't have at least one word in the 'sms' column\n",
        "smote_df = smote_df[smote_df[text_column].str.strip().str.len() > 0]\n",
        "\n",
        "# Prompt user to drop NaN rows if any exist\n",
        "if num_nans > 0:\n",
        "    print(f\"The SMOTE-generated dataset contains {num_nans} NaN values.\")\n",
        "    drop_nans = input(\"Do you want to drop the corresponding rows? (y/n): \")\n",
        "    if drop_nans.lower() == \"y\":\n",
        "        smote_df.dropna(inplace=True)\n",
        "        num_nans = smote_df.isna().sum().sum()\n",
        "        print(f\"{num_nans} NaN values were removed.\")\n",
        "    else:\n",
        "        print(\"No rows were dropped.\")\n",
        "\n",
        "smote_file = os.path.splitext(input_file)[0] + \"_SMOTE.csv\"\n",
        "smote_df.to_csv(smote_file, index=False)\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Original Dataset: {input_file}\")\n",
        "print(f\"Total Rows: {len(df)}\")\n",
        "print(f\"Class Counts: {class_counts}\")\n",
        "print(f\"Class Ratios: \\n{(class_counts / len(df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Downsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Downsampled Dataset: {downsampled_file}\")\n",
        "print(f\"Total Rows: {len(downsampled_df)}\")\n",
        "print(f\"Class Counts: {downsampled_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(downsampled_df[label_column].value_counts() / len(downsampled_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Upsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Upsampled Dataset: {upsampled_file}\")\n",
        "print(f\"Total Rows: {len(upsampled_df)}\")\n",
        "print(f\"Class Counts: {upsampled_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(upsampled_df[label_column].value_counts() / len(upsampled_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SMOTE Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"SMOTE Dataset: {smote_file}\")\n",
        "print(f\"Total Rows: {len(smote_df)}\")\n",
        "print(f\"Class Counts: {smote_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(smote_df[label_column].value_counts() / len(smote_df)).round(3)}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc1_rZrRQ2ix",
        "outputId": "62b13d93-72bc-48a7-b0f0-536038089528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the name of the input file: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training.csv\n",
            "Enter the name of the text column: TEXT\n",
            "Enter the name of the label column: LABEL\n",
            "\n",
            "================================================================================\n",
            "                                Dataset Summary                                 \n",
            "================================================================================\n",
            "Original Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training.csv\n",
            "Total Rows: 4164\n",
            "Class Counts: ham         3383\n",
            "smishing     440\n",
            "spam         341\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.812\n",
            "smishing    0.106\n",
            "spam        0.082\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          Downsampled Dataset Summary                           \n",
            "================================================================================\n",
            "Downsampled Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_downsampled.csv\n",
            "Total Rows: 1023\n",
            "Class Counts: ham         341\n",
            "smishing    341\n",
            "spam        341\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "smishing    0.333\n",
            "spam        0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           Upsampled Dataset Summary                            \n",
            "================================================================================\n",
            "Upsampled Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_upsampled.csv\n",
            "Total Rows: 10149\n",
            "Class Counts: ham         3383\n",
            "smishing    3383\n",
            "spam        3383\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "smishing    0.333\n",
            "spam        0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             SMOTE Dataset Summary                              \n",
            "================================================================================\n",
            "SMOTE Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_SMOTE.csv\n",
            "Total Rows: 10147\n",
            "Class Counts: spam        3383\n",
            "smishing    3383\n",
            "ham         3381\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "spam        0.333\n",
            "smishing    0.333\n",
            "ham         0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Prompt user for input file\n",
        "input_file = input(\"Enter the name of the input file: \")\n",
        "\n",
        "# Prompt user for column name of the text data\n",
        "text_column = input(\"Enter the name of the text column: \")\n",
        "\n",
        "# Prompt user for the column name of the binary labels\n",
        "label_column = input(\"Enter the name of the label column: \")\n",
        "\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Convert class names to lowercase\n",
        "df[label_column] = df[label_column].str.lower()\n",
        "\n",
        "# Recalculate class counts and ratios\n",
        "class_counts = df[label_column].value_counts()\n",
        "\n",
        "# Find the size of the largest and smallest class\n",
        "max_class_size = class_counts.max()\n",
        "min_class_size = class_counts.min()\n",
        "\n",
        "# Upsample the minority classes\n",
        "upsampled_df = pd.DataFrame()\n",
        "for class_value in class_counts.index:\n",
        "    class_data = df[df[label_column] == class_value]\n",
        "    upsampled_data = resample(class_data, replace=True, n_samples=max_class_size, random_state=42)\n",
        "    upsampled_df = pd.concat([upsampled_df, upsampled_data])\n",
        "\n",
        "# Downsample the majority class\n",
        "downsampled_df = pd.DataFrame()\n",
        "for class_value in class_counts.index:\n",
        "    class_data = df[df[label_column] == class_value]\n",
        "    downsampled_data = resample(class_data, replace=False, n_samples=min_class_size, random_state=42)\n",
        "    downsampled_df = pd.concat([downsampled_df, downsampled_data])\n",
        "\n",
        "# Save the upsampled and downsampled dataframes to CSV files\n",
        "upsampled_file = os.path.splitext(input_file)[0] + \"_upsampled.csv\"\n",
        "upsampled_df.to_csv(upsampled_file, index=False)\n",
        "\n",
        "downsampled_file = os.path.splitext(input_file)[0] + \"_downsampled.csv\"\n",
        "downsampled_df.to_csv(downsampled_file, index=False)\n",
        "\n",
        "# Use SMOTE to achieve balance in the dataset\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[text_column])\n",
        "y = df[label_column]\n",
        "\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=10)  # Increase k_neighbors to 10\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Ensure the inverse_transform function returns proper strings\n",
        "smote_texts = [' '.join(text) if len(text) > 0 else '' for text in vectorizer.inverse_transform(X_resampled)]\n",
        "\n",
        "smote_df = pd.DataFrame({text_column: smote_texts, label_column: y_resampled})\n",
        "\n",
        "# Drop rows with NaN values\n",
        "smote_df.dropna(inplace=True)\n",
        "\n",
        "# Check for NaN values in the dataframe\n",
        "num_nans = smote_df.isna().sum().sum()\n",
        "\n",
        "# Drop rows that don't have at least one word in the 'sms' column\n",
        "smote_df = smote_df[smote_df[text_column].str.strip().str.len() > 0]\n",
        "\n",
        "# Prompt user to drop NaN rows if any exist\n",
        "if num_nans > 0:\n",
        "    print(f\"The SMOTE-generated dataset contains {num_nans} NaN values.\")\n",
        "    drop_nans = input(\"Do you want to drop the corresponding rows? (y/n): \")\n",
        "    if drop_nans.lower() == \"y\":\n",
        "        smote_df.dropna(inplace=True)\n",
        "        num_nans = smote_df.isna().sum().sum()\n",
        "        print(f\"{num_nans} NaN values were removed.\")\n",
        "    else:\n",
        "        print(\"No rows were dropped.\")\n",
        "\n",
        "smote_file = os.path.splitext(input_file)[0] + \"_SMOTE.csv\"\n",
        "smote_df.to_csv(smote_file, index=False)\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Original Dataset: {input_file}\")\n",
        "print(f\"Total Rows: {len(df)}\")\n",
        "print(f\"Class Counts: {class_counts}\")\n",
        "print(f\"Class Ratios: \\n{(class_counts / len(df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Downsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Downsampled Dataset: {downsampled_file}\")\n",
        "print(f\"Total Rows: {len(downsampled_df)}\")\n",
        "print(f\"Class Counts: {downsampled_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(downsampled_df[label_column].value_counts() / len(downsampled_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Upsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Upsampled Dataset: {upsampled_file}\")\n",
        "print(f\"Total Rows: {len(upsampled_df)}\")\n",
        "print(f\"Class Counts: {upsampled_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(upsampled_df[label_column].value_counts() / len(upsampled_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SMOTE Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"SMOTE Dataset: {smote_file}\")\n",
        "print(f\"Total Rows: {len(smote_df)}\")\n",
        "print(f\"Class Counts: {smote_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(smote_df[label_column].value_counts() / len(smote_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwsAJmNn-VI4",
        "outputId": "7970a48a-8a8d-4760-f69b-891af1b394ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the name of the input file: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training.csv\n",
            "Enter the name of the text column: TEXT\n",
            "Enter the name of the label column: LABEL\n",
            "\n",
            "================================================================================\n",
            "                                Dataset Summary                                 \n",
            "================================================================================\n",
            "Original Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training.csv\n",
            "Total Rows: 4164\n",
            "Class Counts: ham         3383\n",
            "smishing     440\n",
            "spam         341\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.812\n",
            "smishing    0.106\n",
            "spam        0.082\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          Downsampled Dataset Summary                           \n",
            "================================================================================\n",
            "Downsampled Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_downsampled.csv\n",
            "Total Rows: 1023\n",
            "Class Counts: ham         341\n",
            "smishing    341\n",
            "spam        341\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "smishing    0.333\n",
            "spam        0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           Upsampled Dataset Summary                            \n",
            "================================================================================\n",
            "Upsampled Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_upsampled.csv\n",
            "Total Rows: 10149\n",
            "Class Counts: ham         3383\n",
            "smishing    3383\n",
            "spam        3383\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "smishing    0.333\n",
            "spam        0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             SMOTE Dataset Summary                              \n",
            "================================================================================\n",
            "SMOTE Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_SMOTE.csv\n",
            "Total Rows: 10147\n",
            "Class Counts: spam        3383\n",
            "smishing    3383\n",
            "ham         3381\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "spam        0.333\n",
            "smishing    0.333\n",
            "ham         0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import ADASYN, BorderlineSMOTE\n",
        "\n",
        "\n",
        "# Connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Prompt user for input file\n",
        "input_file = input(\"Enter the name of the input file: \")\n",
        "\n",
        "# Prompt user for column name of the text data\n",
        "text_column = input(\"Enter the name of the text column: \")\n",
        "\n",
        "# Prompt user for the column name of the binary labels\n",
        "label_column = input(\"Enter the name of the label column: \")\n",
        "\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Convert class names to lowercase\n",
        "df[label_column] = df[label_column].str.lower()\n",
        "\n",
        "# Recalculate class counts and ratios\n",
        "class_counts = df[label_column].value_counts()\n",
        "\n",
        "# Find the size of the largest and smallest class\n",
        "max_class_size = class_counts.max()\n",
        "min_class_size = class_counts.min()\n",
        "\n",
        "# Upsample the minority classes\n",
        "upsampled_df = pd.DataFrame()\n",
        "for class_value in class_counts.index:\n",
        "    class_data = df[df[label_column] == class_value]\n",
        "    upsampled_data = resample(class_data, replace=True, n_samples=max_class_size, random_state=42)\n",
        "    upsampled_df = pd.concat([upsampled_df, upsampled_data])\n",
        "\n",
        "# Downsample the majority class\n",
        "downsampled_df = pd.DataFrame()\n",
        "for class_value in class_counts.index:\n",
        "    class_data = df[df[label_column] == class_value]\n",
        "    downsampled_data = resample(class_data, replace=False, n_samples=min_class_size, random_state=42)\n",
        "    downsampled_df = pd.concat([downsampled_df, downsampled_data])\n",
        "\n",
        "# Save the upsampled and downsampled dataframes to CSV files\n",
        "upsampled_file = os.path.splitext(input_file)[0] + \"_upsampled.csv\"\n",
        "upsampled_df.to_csv(upsampled_file, index=False)\n",
        "\n",
        "downsampled_file = os.path.splitext(input_file)[0] + \"_downsampled.csv\"\n",
        "downsampled_df.to_csv(downsampled_file, index=False)\n",
        "\n",
        "# Use SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n",
        "\n",
        "# Use ADASYN\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X, y)\n",
        "\n",
        "# Use BorderlineSMOTE\n",
        "borderline_smote = BorderlineSMOTE(random_state=42)\n",
        "X_resampled_borderline, y_resampled_borderline = borderline_smote.fit_resample(X, y)\n",
        "\n",
        "# Ensure the inverse_transform function returns proper strings\n",
        "smote_texts = [' '.join(text) if len(text) > 0 else '' for text in vectorizer.inverse_transform(X_resampled_smote)]\n",
        "adasyn_texts = [' '.join(text) if len(text) > 0 else '' for text in vectorizer.inverse_transform(X_resampled_adasyn)]\n",
        "borderline_texts = [' '.join(text) if len(text) > 0 else '' for text in vectorizer.inverse_transform(X_resampled_borderline)]\n",
        "\n",
        "smote_df = pd.DataFrame({text_column: smote_texts, label_column: y_resampled_smote})\n",
        "adasyn_df = pd.DataFrame({text_column: adasyn_texts, label_column: y_resampled_adasyn})\n",
        "borderline_df = pd.DataFrame({text_column: borderline_texts, label_column: y_resampled_borderline})\n",
        "\n",
        "# Drop rows with NaN values\n",
        "smote_df.dropna(inplace=True)\n",
        "\n",
        "# Check for NaN values in the dataframe\n",
        "num_nans = smote_df.isna().sum().sum()\n",
        "\n",
        "# Drop rows that don't have at least one word in the 'sms' column\n",
        "smote_df = smote_df[smote_df[text_column].str.strip().str.len() > 0]\n",
        "\n",
        "# Prompt user to drop NaN rows if any exist\n",
        "if num_nans > 0:\n",
        "    print(f\"The SMOTE-generated dataset contains {num_nans} NaN values.\")\n",
        "    drop_nans = input(\"Do you want to drop the corresponding rows? (y/n): \")\n",
        "    if drop_nans.lower() == \"y\":\n",
        "        smote_df.dropna(inplace=True)\n",
        "        num_nans = smote_df.isna().sum().sum()\n",
        "        print(f\"{num_nans} NaN values were removed.\")\n",
        "    else:\n",
        "        print(\"No rows were dropped.\")\n",
        "\n",
        "smote_file = os.path.splitext(input_file)[0] + \"_SMOTE.csv\"\n",
        "smote_df.to_csv(smote_file, index=False)\n",
        "\n",
        "adasyn_file = os.path.splitext(input_file)[0] + \"_ADASYN.csv\"\n",
        "adasyn_df.to_csv(adasyn_file, index=False)\n",
        "\n",
        "borderline_file = os.path.splitext(input_file)[0] + \"_BorderlineSMOTE.csv\"\n",
        "borderline_df.to_csv(borderline_file, index=False)\n",
        "\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Original Dataset: {input_file}\")\n",
        "print(f\"Total Rows: {len(df)}\")\n",
        "print(f\"Class Counts: {class_counts}\")\n",
        "print(f\"Class Ratios: \\n{(class_counts / len(df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Downsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Downsampled Dataset: {downsampled_file}\")\n",
        "print(f\"Total Rows: {len(downsampled_df)}\")\n",
        "print(f\"Class Counts: {downsampled_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(downsampled_df[label_column].value_counts() / len(downsampled_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Upsampled Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"Upsampled Dataset: {upsampled_file}\")\n",
        "print(f\"Total Rows: {len(upsampled_df)}\")\n",
        "print(f\"Class Counts: {upsampled_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(upsampled_df[label_column].value_counts() / len(upsampled_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SMOTE Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"SMOTE Dataset: {smote_file}\")\n",
        "print(f\"Total Rows: {len(smote_df)}\")\n",
        "print(f\"Class Counts: {smote_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(smote_df[label_column].value_counts() / len(smote_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ADASYN Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"ADASYN Dataset: {adasyn_file}\")\n",
        "print(f\"Total Rows: {len(adasyn_df)}\")\n",
        "print(f\"Class Counts: {adasyn_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(adasyn_df[label_column].value_counts() / len(adasyn_df)).round(3)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BorderlineSMOTE Dataset Summary\".center(80))\n",
        "print(\"=\"*80)\n",
        "print(f\"BorderlineSMOTE Dataset: {borderline_file}\")\n",
        "print(f\"Total Rows: {len(borderline_df)}\")\n",
        "print(f\"Class Counts: {borderline_df[label_column].value_counts()}\")\n",
        "print(f\"Class Ratios: \\n{(borderline_df[label_column].value_counts() / len(borderline_df)).round(3)}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "outputId": "a0a7dff9-4136-436a-a60f-099521048fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1cICCWBA4HP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the name of the input file: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training.csv\n",
            "Enter the name of the text column: TEXT\n",
            "Enter the name of the label column: LABEL\n",
            "\n",
            "================================================================================\n",
            "                                Dataset Summary                                 \n",
            "================================================================================\n",
            "Original Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training.csv\n",
            "Total Rows: 4164\n",
            "Class Counts: ham         3383\n",
            "smishing     440\n",
            "spam         341\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.812\n",
            "smishing    0.106\n",
            "spam        0.082\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          Downsampled Dataset Summary                           \n",
            "================================================================================\n",
            "Downsampled Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_downsampled.csv\n",
            "Total Rows: 1023\n",
            "Class Counts: ham         341\n",
            "smishing    341\n",
            "spam        341\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "smishing    0.333\n",
            "spam        0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           Upsampled Dataset Summary                            \n",
            "================================================================================\n",
            "Upsampled Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_upsampled.csv\n",
            "Total Rows: 10149\n",
            "Class Counts: ham         3383\n",
            "smishing    3383\n",
            "spam        3383\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "smishing    0.333\n",
            "spam        0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             SMOTE Dataset Summary                              \n",
            "================================================================================\n",
            "SMOTE Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_SMOTE.csv\n",
            "Total Rows: 10147\n",
            "Class Counts: spam        3383\n",
            "smishing    3383\n",
            "ham         3381\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "spam        0.333\n",
            "smishing    0.333\n",
            "ham         0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             ADASYN Dataset Summary                             \n",
            "================================================================================\n",
            "ADASYN Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_ADASYN.csv\n",
            "Total Rows: 10201\n",
            "Class Counts: smishing    3441\n",
            "ham         3383\n",
            "spam        3377\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "smishing    0.337\n",
            "ham         0.332\n",
            "spam        0.331\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                        BorderlineSMOTE Dataset Summary                         \n",
            "================================================================================\n",
            "BorderlineSMOTE Dataset: /content/drive/MyDrive/Production Datasets/1_Praxis_Dataset/DeDuped_Dataset/Split Dataset/Training Data/Dataset_5971_deduped_training_BorderlineSMOTE.csv\n",
            "Total Rows: 10149\n",
            "Class Counts: ham         3383\n",
            "spam        3383\n",
            "smishing    3383\n",
            "Name: LABEL, dtype: int64\n",
            "Class Ratios: \n",
            "ham         0.333\n",
            "spam        0.333\n",
            "smishing    0.333\n",
            "Name: LABEL, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}